**Experiment Title**: Sentiment Analysis Model Comparison (LSTM vs Transformer)
**Date**: 1.7.2025
**Objective**: Compare LSTM and Transformer models for sentiment analysis on IMDB reviews.

**Dataset**: IMDB Reviews dataset.
**Experiment Configuration**:
    - Model: LSTM (or Transformer)
    - Hyperparameters:
        - Learning Rate: 0.001
        - Batch Size: 64
        - Epochs: 10
        - Optimizer: Adam

**Results**:
    - Model Performance:
        - Accuracy: 85%
        - F1-Score: 0.78
        - Precision: 0.80
        - Recall: 0.76

**Notes**:
    - Challenges: LSTM took longer to train; Transformer showed better results.
    - Insights: Transformer had slightly better accuracy but took longer to train.

